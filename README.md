# HeyLisa Backend

Backend Python (FastAPI) de **HeyLisa** â€” Assistante IA exÃ©cutive.  
Ce service constitue le **socle backend applicatif** (logique mÃ©tier, accÃ¨s DB, orchestration), distinct :
- du frontend mobile (Expo / React Native)
- des workflows n8n (automations, webhooks)
- de Supabase (auth + base de donnÃ©es managÃ©e)

---

## ğŸ¯ Objectifs du backend (vision)

- Fournir des **endpoints applicatifs stables** (Context Loader, Quota, Lisa runtime, etc.)
- Centraliser la **logique mÃ©tier critique** (quotas, droits, modes, rÃ¨gles)
- Garantir un accÃ¨s **DB asynchrone performant** (asyncpg)
- ÃŠtre dÃ©ployable facilement (Railway dev/prod)

âš ï¸ Ã€ ce stade, le backend est volontairement **minimal** : on pose le socle proprement avant dâ€™empiler la logique.

---

## ğŸ§± Stack technique

- **Python 3.11**
- **FastAPI** â€” framework API
- **Uvicorn** â€” serveur ASGI
- **asyncpg** â€” driver PostgreSQL asynchrone (choix actÃ©)
- **pydantic-settings** â€” gestion des variables dâ€™environnement
- **structlog** â€” logging structurÃ©
- **Supabase Postgres** â€” base de donnÃ©es (externe)

---

## ğŸ“ Structure du projet

heylisa-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/            # Routes API (ex: health)
â”‚   â”œâ”€â”€ core/           # Config & logging
â”‚   â”œâ”€â”€ init.py
â”‚   â””â”€â”€ main.py         # EntrÃ©e FastAPI
â”‚
â”œâ”€â”€ heylisa-n8n/        # Assets / flows n8n liÃ©s (hors scope backend pur)
â”œâ”€â”€ supabase_schema_prod.sql
â”‚
â”œâ”€â”€ .env                # Variables locales (non versionnÃ©)
â”œâ”€â”€ .env.example        # Template dâ€™env
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ runtime.txt         # Version Python pour Railway
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

---

## âš™ï¸ Setup local

### 1) Environnement Python

```bash
python3 -m venv .venv

#### Activer l'environnement virtuel
source .venv/bin/activate

VÃ©rification :

which python
python3 --version
# => Python 3.11.x depuis .venv

2) Installation des dÃ©pendances
pip install -r requirements.txt

Contenu actuel :
fastapi
uvicorn[standard]
python-dotenv
pydantic-settings
structlog
httpx
asyncpg

3) Variables dâ€™environnement

CrÃ©er .env Ã  la racine (ne jamais committer) :

DATABASE_URL=postgresql://postgres:PASSWORD@db.<project-ref>.supabase.co:5432/postgres
ENVIRONMENT=dev
LOG_LEVEL=INFO

âš ï¸ Important :
	â€¢	Ne pas mettre de crochets [] autour du password dans lâ€™URL (sinon asyncpg casse).
	â€¢	Pour Supabase : choisir Direct connection pour usage â€œservice backend / long-livedâ€.
	â€¢	En dev local, lâ€™IP allowlist Supabase peut Ãªtre requise selon ta config.

ğŸ‘‰ DATABASE_URL correspond Ã  la connection string Supabase
(Supabase â†’ Settings â†’ Database â†’ Connection string).

â¸»

4) Lancer le serveur en local (commande standard)

âš ï¸ Commande officielle recommandÃ©e (Ã©vite les soucis de PATH) :
python3 -m uvicorn app.main:app --reload --port 8000

âš ï¸ Commande simple
uvicorn app.main:app --reload --port 8000

âœ… Health check

Endpoints :
GET /health

Test : 
curl -s http://127.0.0.1:8000/health | python3 -m json.tool


RÃ©ponse attendue : 
{
  "status": "healthy",
  "environment": "dev",
  "version": "0.1.0",
  "timestamp": "2026-02-06T02:45:14.538215"
}

GET /v1/quota/{public_user_id}

Test : 
curl -s http://127.0.0.1:8000/v1/quota/<PUBLIC_USER_ID> | python3 -m json.tool

Retourne lâ€™Ã©tat quota dâ€™un user (read-only) :

RÃ©ponse :
{
  "public_user_id": "...",
  "is_pro": false,
  "free_quota_used": 6,
  "free_quota_limit": 8,
  "state": "normal",
  "paywall_should_show": false
}

VOIR LES LOGS DU CHAT

A) Voir tout le chat tracing
python3 -m uvicorn app.main:app --reload --port 8000 | grep heylisa.chat

B) Voir uniquement les events (encore plus strict)
python3 -m uvicorn app.main:app --reload --port 8000 | grep '"logger": "heylisa.chat"'

C) Voir juste les nodes
python3 -m uvicorn app.main:app --reload --port 8000 | grep '"event": "chat.node.'

(sur mac, grep marche direct)


RÃ¨gles Quota (v1)

Tables utilisÃ©es
	â€¢	public.users.is_pro (source de vÃ©ritÃ© abonnement)
	â€¢	public.user_settings.free_quota_used (compteur)
	â€¢	public.user_settings.free_quota_limit (limit)

Invariants
	â€¢	On ne reset jamais free_quota_used (quota free â€œlifetimeâ€)
	â€¢	state calculÃ© backend (aide Lisa + logique cÃ´tÃ© services) :
	â€¢	normal si used < limit - 1
	â€¢	warn_last_free si used == limit - 1 (ex: message #7 si limit=8)
	â€¢	blocked si used >= limit

Paywall
	â€¢	Le front doit afficher paywall si :
	â€¢	!isPro && free_quota_used >= free_quota_limit
	â€¢	Câ€™est volontairement un pont direct DB <-> front en realtime (option A).
	â€¢	Le backend sert surtout Ã  fournir un Ã©tat consolidÃ© (state) pour Lisa / services.

ğŸ“œ Journal dâ€™implÃ©mentation

2026-02-06 â€” Backend v0 stabilisÃ©

But
	â€¢	Poser un socle backend propre avant toute logique mÃ©tier.
	â€¢	PrÃ©parer lâ€™intÃ©gration future des endpoints (Quota, Context Loader, Lisa).

RÃ©alisÃ©
	â€¢	Initialisation FastAPI fonctionnelle
	â€¢	Logging structurÃ© en place
	â€¢	Endpoint /health opÃ©rationnel
	â€¢	Environnement Python isolÃ© (.venv)
	â€¢	Choix technique actÃ© : asyncpg pour PostgreSQL
	â€¢	Commandes de run standardisÃ©es (python3 -m uvicorn)
	â€¢	CompatibilitÃ© Railway (runtime.txt)

DÃ©cisions techniques clÃ©s
	â€¢	DB driver : asyncpg (asynchrone, performant)
	â€¢	Backend volontairement minimal au dÃ©part
	â€¢	Documentation tenue au fil de lâ€™eau (pas de dette doc)

â¸»

ğŸš§ Ce qui nâ€™est PAS encore implÃ©mentÃ© (volontairement)
	â€¢	Pool de connexion DB
	â€¢	Endpoints mÃ©tier (quota, context loader, etc.)
	â€¢	Auth backend (repose encore sur Supabase cÃ´tÃ© front)
	â€¢	SÃ©curitÃ© avancÃ©e (RLS backend, scopes, etc.)

ğŸ‘‰ Ces Ã©lÃ©ments seront ajoutÃ©s Ã©tape par Ã©tape, chacun documentÃ© dans ce journal.

â¸»

â–¶ï¸ Prochaines Ã©tapes prÃ©vues
	1.	Ajout du module DB asyncpg (pool)
	2.	Service Quota standalone (sans branchement front)
	3.	Endpoint /quota/status
	4.	Puis intÃ©gration progressive au Context Loader

â¸»

ğŸ§  RÃ¨gle de gouvernance

Toute Ã©volution backend doit :
	â€¢	Ãªtre commitÃ©e
	â€¢	Ãªtre documentÃ©e ici (quoi / pourquoi / contraintes)
	â€¢	ne pas casser lâ€™existant sans dÃ©cision explicite


## ğŸ§  Chat Engine â€” Ã‰tat actuel (fÃ©vrier 2026)

Architecture gÃ©nÃ©rale
	â€¢	Frontend (Expo / React Native)
	â€¢	UI chat optimiste + DB source of truth
	â€¢	Gestion fine des Ã©tats :
	â€¢	isLisaBusy
	â€¢	isLisaThinking
	â€¢	isSlowThinking
	â€¢	Aucun message Lisa nâ€™est Ã©crit cÃ´tÃ© front (sauf fallback local UX)
	â€¢	Backend (API Chat)
	â€¢	Endpoint principal :
	POST /v1/chat/message


	â€¢	Le backend est lâ€™unique source de vÃ©ritÃ© pour :
	â€¢	la crÃ©ation des messages Lisa
	â€¢	la persistance en base
	â€¢	la logique mÃ©tier (quota, routing, agents Ã  venir)

â¸»

Flux dâ€™un message utilisateur
	1.	Lâ€™utilisateur envoie un message depuis le front
	2.	Le message est sauvegardÃ© immÃ©diatement en base (conversation_messages)
	3.	Le front affiche le message en optimiste
	4.	Le front appelle :
POST /v1/chat/message

avec :

{
  "conversation_id": "...",
  "user_message_id": "..."
}

	5.	Le backend traite le message (logique en cours dâ€™extension)
	6.	Le front recharge lâ€™historique depuis la DB
ğŸ‘‰ UI 100% alignÃ©e DB, zÃ©ro divergence

â¸»

Gestion des erreurs (front)
	â€¢	Erreurs rÃ©seau / front
	â€¢	Pas de fallback backend
	â€¢	Pas dâ€™Ã©criture DB
	â€¢	Message UX local Lisa :
â€œJe nâ€™arrive pas Ã  joindre le serveur. RÃ©essaie dans quelques secondes ğŸ™â€
	â€¢	Le message utilisateur est restaurÃ© dans le champ si non sauvegardÃ©
	â€¢	Erreurs backend
	â€¢	Fallback Lisa local (pas DB)
	â€¢	Aucun Ã©tat bloquant (watchdog UI)
	â€¢	Watchdogs
	â€¢	Soft warning aprÃ¨s 25s (isSlowThinking)
	â€¢	Hard UI release aprÃ¨s 5 min (anti â€œLisa thinking infiniâ€)

â¸»

Configuration environnement
	â€¢	Le frontend utilise dynamiquement :

BACKEND_BASE_URL

injectÃ© via :
	â€¢	app.config.ts
	â€¢	extra.backend.baseUrl
	â€¢	fallback local http://127.0.0.1:8000

	â€¢	En production :
https://api.heylisa.io

ğŸ‘‰ Aucun changement front requis entre dev / prod.

â¸»

Ã‰tat de stabilitÃ©
	â€¢	âœ… Chat fonctionnel en DEV
	â€¢	âœ… Paywall backend-compatible
	â€¢	âœ… UX fluide (typing, scroll, erreurs)
	â€¢	âœ… Architecture validÃ©e pour extension (agents, routing, onboarding)


## Pilotage des LLMs : rÃ¨gle actÃ©e (simple et saine)

1ï¸âƒ£ Choix des providers

On grave Ã§a dans le marbre :

Ordre dâ€™appel
	1.	DeepSeek â†’ provider primaire
	2.	OpenAI 4o-mini â†’ fallback uniquement

Principe
	â€¢	Le backend ne sait pas â€œquel agentâ€ utilise quel LLM.
	â€¢	Il appelle un LLM runtime unique.
	â€¢	Ce runtime :
	â€¢	tente DeepSeek
	â€¢	si erreur / timeout / output invalide â†’ fallback OpenAI
	â€¢	renvoie { text, provider }

ğŸ‘‰ Tu lâ€™as dÃ©jÃ  implicitement fait dans le chat engine, on ne change rien, on gÃ©nÃ©ralise.

â¸»

2ï¸âƒ£ TrÃ¨s bon point : ne PAS figer les outputs de tous les agents

Tu as 100% raison.

âŒ Erreur classique Ã  Ã©viter

â€œOn dÃ©finit dÃ¨s maintenant les JSON outputs de 12 agents quâ€™on nâ€™a pas encore vraiment Ã©prouvÃ©sâ€

RÃ©sultat habituel :
	â€¢	rigiditÃ© prÃ©maturÃ©e
	â€¢	refactors incessants
	â€¢	perte de vitesse

â¸»

3ï¸âƒ£ La bonne stratÃ©gie (ce que je te recommande fortement)

âœ… Ce quâ€™on fixe MAINTENANT

Seulement les invariants systÃ©miques, pas les mÃ©tiers :

A. Convention universelle dâ€™output agent

Tous les agents doivent respecter au moins ceci :

{
  "confidence": 0.0,
  "decision": "...",
  "notes": "...",
  "payload": {}
}

	â€¢	confidence âˆˆ [0,1] â†’ obligatoire
	â€¢	decision â†’ string courte (routing, choix contexte, etc.)
	â€¢	notes â†’ explicatif humain (debug / logs / observabilitÃ©)
	â€¢	payload â†’ libre, Ã©volutif, spÃ©cifique Ã  lâ€™agent

ğŸ‘‰ Le backend ne fait confiance Ã  un agent que si confidence â‰¥ 0.8
Sinon â†’ fallback dÃ©terministe (LIGHT context, rÃ©ponse safe, etc.)

Câ€™est LA rÃ¨gle critique


â¸»

B. System messages & prompts : figÃ©s, mais extensibles

On fige :
	â€¢	la structure
	â€¢	la philosophie
	â€¢	les garde-fous

On nâ€™Ã©numÃ¨re pas :
	â€¢	tous les agents
	â€¢	tous les champs
	â€¢	tous les cas

â¸»

4ï¸âƒ£ Organisation concrÃ¨te des prompts (v1 rÃ©aliste)

app/prompts/
  system/
    lisa_persona.md
    safety.md
    output_contract.md   # â† le JSON minimal ci-dessus
  agents/
    intent_classifier.md
    router.md
    onboarding.md
    response_generator.md


	â€¢	Chaque prompt est indÃ©pendant
	â€¢	Le backend compose dynamiquement
	â€¢	Aucun prompt â€œgÃ©ant universelâ€

â¸»

5ï¸âƒ£ Comment le backend orchestre sans sur-spÃ©cifier


 âœ… Backend agentique (Orchestration)

Request
    â†“
Orchestrator (dÃ©cide du plan)
    â†“
Agent Graph (DAG - Directed Acyclic Graph)
    â”œâ”€â†’ Agent A (parallÃ¨le)
    â”œâ”€â†’ Agent B (parallÃ¨le)
    â”‚     â†“
    â””â”€â†’ Agent C (sÃ©quentiel, dÃ©pend de A+B)
          â†“
       Agent D (synthÃ¨se)
    â†“
Response

Non-linÃ©aire, adaptatif, asynchrone


Mico-Exemple logique simplifiÃ©e (pseudo-flow)

message user
   â†“
IntentClassifierAgent
   â†’ confidence < 0.8 ? fallback general
   â†“
RouterAgent
   â†’ choisit context_level (light / medium / max)
   â†’ confidence < 0.8 ? force light
   â†“
ContextLoader(context_level)
   â†“
ResponseGeneratorAgent


Ã€ aucun moment :
	â€¢	le backend nâ€™impose une structure mÃ©tier rigide
	â€¢	le backend ne â€œdevineâ€ Ã  la place de Lisa

ğŸ‘‰ Lisa dÃ©cide, le backend valide et borne.

â¸»

6ï¸âƒ£ OÃ¹ vivent les rÃ¨gles mÃ©tier (important)

Ã‰lÃ©ment
OÃ¹
Persona Lisa > system prompt
Anti-patterns > system prompt
Choix contexte > agent router
Limites quota > backend
Fallback sÃ©curitÃ© > backend
Langue / timezone > context loader
ProactivitÃ© > agent + cron / jobs

ğŸ‘‰ Le backend est le gendarme, pas lâ€™intelligence.

â¸»

7ï¸âƒ£ Ce qui est verrouillÃ© 

On a :
	â€¢	un runtime LLM propre
	â€¢	une architecture agentique contrÃ´lÃ©e
	â€¢	une Ã©volution incrÃ©mentale possible
	â€¢	zÃ©ro dette de prompt prÃ©maturÃ©e
	â€¢	une Lisa qui reste maÃ®tresse de ses dÃ©cisions


---

## ğŸ“œ Journal dâ€™implÃ©mentation

### 2026-02-07 â€” Chat Engine v1 (Orchestrator + PlanExecutor + ResponseWriter) âœ…

Objectif
- Passer dâ€™un â€œchat direct LLMâ€ Ã  une architecture **agentique contrÃ´lÃ©e** (DAG) :
  - Orchestrator = dÃ©cide intent / contexte / besoin web / plan
  - PlanExecutor = exÃ©cute le plan (tools + agents)
  - ResponseWriter (Lisa) = gÃ©nÃ¨re la rÃ©ponse finale avec conventions UI stables

RÃ©alisÃ©
- âœ… **OrchestratorAgent** (LLM) qui produit un plan DAG JSON :
  - DÃ©tection `intent`, `context_level`, `need_web`, `web_search_prompt`
  - GÃ©nÃ©ration du plan via une **whitelist stricte** de nodes
  - Guardrails : confidence, cohÃ©rence need_web, contraintes amabilities
- âœ… **PlanExecutor** :
  - ExÃ©cution topo simple basÃ©e sur `depends_on`
  - ExÃ©cution des nodes autorisÃ©s :
    - `tool.db_load_context` (context loader)
    - `tool.quota_check` (statut quota)
    - `tool.web_search` (Perplexity sonar-pro)
    - `agent.response_writer` (Lisa)
  - **Verrou â€œanswer-onlyâ€** : sortie toujours une string safe (fallback + truncation)
  - **Hard allowlist** cÃ´tÃ© executor : tout node non autorisÃ© est rejetÃ©
- âœ… **ResponseWriterAgent (Lisa)** :
  - System prompt stable + anti-patterns + rÃ¨gles intent
  - **Conventions UI** pour rÃ©ponses â€œchat-safeâ€ (pas de HTML, pas de markdown complexe)
  - Gestion des sources web :
    - Affiche au besoin un bloc `ğŸ“Œ Sources` (1 Ã  3 puces, sans URL)
    - Nâ€™injecte au modÃ¨le que titres + domaines (pas de liens bruts)
  - Compat params : `web=` + fallback `web_search=`

DÃ©cisions techniques clÃ©s
- **Architecture agentique (DAG) contrÃ´lÃ©e**
  - Le backend exÃ©cute, borne et valide.
  - Lâ€™intelligence est rÃ©partie : orchestrator (plan) + lisa (rÃ©daction).
- **Whitelisting strict des nodes**
  - Source de vÃ©ritÃ© : `app/agents/node_registry.py`
  - UtilisÃ© par :
    - lâ€™Orchestrator (dans le prompt + validation)
    - le PlanExecutor (refus hard si type non autorisÃ©)
- **IDs A/B/C/D**
  - Convention simple pour v0 :
    - A = context
    - B = quota
    - C = web_search (si besoin)
    - D = response_writer (final)
  - Lâ€™ordre de traitement rÃ©el reste dÃ©terminÃ© par `depends_on` (pas par la lettre).

Endpoints impactÃ©s
- `POST /v1/chat/message`
  - Devient le point dâ€™entrÃ©e unique :
    - lit message user (DB)
    - orchestre plan
    - exÃ©cute
    - Ã©crit le message Lisa en DB (source of truth)

Gestion des erreurs
- **Niveau Chat (chat.py)**
  - Try/except global : fallback rÃ©ponse safe si crash complet
- **Niveau PlanExecutor**
  - Verrou final â€œanswer-onlyâ€ : mÃªme si response_writer foire, on renvoie une string safe
  - Anti pavÃ© : limite `MAX_ANSWER_CHARS` + ellipsis

Fichiers ajoutÃ©s / modifiÃ©s (v1)
- `app/services/chat.py`
  - Branche OrchestratorAgent + PlanExecutor
  - Persistance DB + idempotence via `assistant_message_id` + `dedupe_key`
- `app/agents/orchestrator.py`
  - Prompt de routing + gÃ©nÃ©ration plan DAG
  - Validation plan + fallback minimal
  - IntÃ©gration whitelist via `node_registry`
- `app/services/plan_executor.py`
  - ExÃ©cution DAG + guardrails answer-only
  - Hard allowlist `NODE_TYPE_WHITELIST`
- `app/agents/response_writer.py`
  - Lisa â€œwriterâ€ : conventions UI + rÃ¨gles intent + sources digest
- `app/tools/web_search.py`
  - Tool web search (Perplexity sonar-pro) JSON strict
- `app/agents/node_registry.py`
  - Source de vÃ©ritÃ© : whitelist node types + rÃ¨gles IDs
  - Helpers de rendu pour inclusion dans le system prompt

Ce qui nâ€™est PAS encore implÃ©mentÃ© (volontairement)
- âŒ ExÃ©cution dâ€™actions rÃ©elles (Ultimate mode : agenda, email, etc.)
- âŒ â€œPro modesâ€ (Medical/Airbnb/etc.) branchÃ©s au routing
- âŒ ParallÃ©lisation rÃ©elle (parallel_group ignorÃ© en v0)
- âŒ ObservabilitÃ© avancÃ©e (traces structurÃ©es par node, metrics, etc.)

Prochaines Ã©tapes prÃ©vues
1. Verrouiller les prompts de lâ€™Orchestrator (tests non-rÃ©gression par intent)
2. Optimisation ResponseWriter (Lisa) :
   - cadrage des entrÃ©es (context, web, intent)
   - anti-robot + concision + style stable
3. (Option) Ajout dâ€™un â€œdebug modeâ€ backend (stockage exec_out.debug en metadata)
4. (Option) ParallÃ©lisation vraie des nodes `parallel_group`

---

